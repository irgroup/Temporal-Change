{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LongEval\n",
    "- filter runs for core queries\n",
    "- filter runs for core docs\n",
    "- filter qrels \n",
    "- harmonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_qrels(subcollection, mode=\"\"):\n",
    "    qrel_paths = {\n",
    "        \"WT\": \"../data/dataset/LongEval/longeval-relevance-judgements/heldout-test.txt\",\n",
    "        \"WT-train\": \"../data/dataset/LongEval/publish/French/Qrels/train.txt\",\n",
    "        \"ST\": \"../data/dataset/LongEval/longeval-relevance-judgements/a-short-july.txt\",\n",
    "        \"LT\": \"../data/dataset/LongEval/longeval-relevance-judgements/b-long-september.txt\",\n",
    "    }\n",
    "\n",
    "    # load core queries\n",
    "    longeval_core_queries = pd.read_csv(\"../evaluation/core_queries.tsv\", sep=\"\\t\", index_col=0)\n",
    "    # load qrels\n",
    "    qrels = pd.read_csv(qrel_paths[subcollection + mode], sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"relevance\"])\n",
    "\n",
    "    patch = longeval_core_queries[f\"qid_{subcollection}\"].reset_index()[[f\"qid_{subcollection}\", \"index\"]].set_index(f\"qid_{subcollection}\")[\"index\"].astype(str).to_dict()\n",
    "\n",
    "    # rename qrels\n",
    "    qrels[\"qid\"] = qrels[\"qid\"].apply(lambda x: patch.get(x, None))\n",
    "\n",
    "    # filter\n",
    "    return qrels.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = filter_qrels(\"WT\")\n",
    "wt_train = filter_qrels(\"WT\", \"-train\")\n",
    "wt = pd.concat([wt, wt_train])\n",
    "wt.to_csv(\"../data/qrels/longeval-WT.qrels-test-core_queries\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = filter_qrels(\"ST\")\n",
    "st.to_csv(\"../data/qrels/longeval-ST.qrels-test-core_queries\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = filter_qrels(\"LT\")\n",
    "st.to_csv(\"../data/qrels/longeval-LT.qrels-test-core_queries\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_runs_metadata_table():\n",
    "    table = []\n",
    "    for run in os.listdir(f\"../data/run\"):\n",
    "        parts = run.split(\"-\")\n",
    "        fields = {\n",
    "            \"dataset\": \"-\".join(parts[1:-4]),\n",
    "            \"subcollection\": parts[-4],\n",
    "            \"queries\": parts[-3],\n",
    "            \"method\": parts[-2],\n",
    "            \"implementation\": parts[-1],\n",
    "            \"filename\": run,\n",
    "        }\n",
    "        table.append(fields)\n",
    "    runs = pd.DataFrame(table)\n",
    "    runs = runs[\n",
    "        ~((runs[\"subcollection\"] == \"WT\") & (runs[\"queries\"] != \"queries\"))\n",
    "    ]  # longeval WT test only\n",
    "    runs = runs[\n",
    "        runs[\"method\"].isin(\n",
    "            [\n",
    "                \"bm25\",\n",
    "                \"bm25+colbert\",\n",
    "                \"bm25+monot5\",\n",
    "                \"rrf(xsqram__bm25_bo1__pl2)\",\n",
    "                \"bm25_d2q10\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_run(row, queries=True):\n",
    "    run = pd.read_csv(\"../data/run/\"+row.filename, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"rank\", \"score\", \"method\"])\n",
    "    \n",
    "    if queries:\n",
    "        longeval_core_queries = pd.read_csv(\"../evaluation/core_queries.tsv\", sep=\"\\t\", index_col=0)\n",
    "        \n",
    "        patch = longeval_core_queries[f\"qid_{row.subcollection}\"].reset_index()[[f\"qid_{row.subcollection}\", \"index\"]].set_index(f\"qid_{row.subcollection}\")[\"index\"].astype(str).to_dict()\n",
    "\n",
    "        run[\"qid\"] = run[\"qid\"].apply(lambda x: patch.get(x, None))\n",
    "    return run.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_table = load_runs_metadata_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in runs_table[runs_table[\"dataset\"] ==\"longeval\"].iterrows():\n",
    "    run = filter_run(row)\n",
    "    run.to_csv(\"../data/run-core_queries/\"+row.filename, sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trec-covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_table = load_runs_metadata_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in runs_table[runs_table[\"dataset\"] ==\"trec-covid\"].iterrows():\n",
    "    run = pd.read_csv(\"../data/run/\"+row.filename, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"rank\", \"score\", \"method\"])\n",
    "    run = run[run[\"qid\"]<=30]\n",
    "    run.to_csv(\"../data/run-core_queries/\"+row.filename, sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip Click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in runs_table[runs_table[\"dataset\"] ==\"tripclick-test-head\"].iterrows():\n",
    "    run = pd.read_csv(\"../data/run/\"+row.filename, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"rank\", \"score\", \"method\"])\n",
    "    run.to_csv(\"../data/run-core_queries/\"+row.filename, sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LongEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
