{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrec_eval\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import ir_datasets\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_runs_metadata_table():\n",
    "    table = []\n",
    "    for run in os.listdir(f\"../data/run\"):\n",
    "        parts = run.split(\"-\")\n",
    "        fields = {\n",
    "            \"dataset\": \"-\".join(parts[1:-4]),\n",
    "            \"subcollection\": parts[-4],\n",
    "            \"queries\": parts[-3],\n",
    "            \"method\": parts[-2],\n",
    "            \"implementation\": parts[-1],\n",
    "            \"filename\": run,\n",
    "        }\n",
    "        table.append(fields)\n",
    "    runs = pd.DataFrame(table)\n",
    "    runs = runs[\n",
    "        ~((runs[\"subcollection\"] == \"WT\") & (runs[\"queries\"] != \"queries\"))\n",
    "    ]  # longeval WT test only\n",
    "    runs = runs[\n",
    "        runs[\"method\"].isin(\n",
    "            [\n",
    "                \"bm25\",\n",
    "                \"bm25+colbert\",\n",
    "                \"bm25+monot5\",\n",
    "                \"rrf(xsqram__bm25_bo1__pl2)\",\n",
    "                \"bm25_d2q10\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trec-Covid\n",
    "### qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ir_dataset_qrels(dataset_name):\n",
    "    dataset = ir_datasets.load(dataset_name)\n",
    "    dataset_name_clean = dataset_name.replace(\"/\", \"-\").replace(\"cord19-\", \"\")\n",
    "    with open(f\"../data/qrels/{dataset_name_clean}.qrels\", \"w\") as file_out:\n",
    "        for qrel in dataset.qrels_iter():\n",
    "            file_out.write(f\"{qrel.query_id} 0 {qrel.doc_id} {qrel.relevance}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_to_core_qrels(qrels_path):\n",
    "    qrels = pd.read_csv(qrels_path, sep=\" \", header=None, names=[\"qid\", \"0\", \"docid\", \"relevance\"])\n",
    "    qrels = qrels[qrels[\"qid\"]<=30]\n",
    "    return qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ir_dataset_qrels(\"cord19/trec-covid/round1\")\n",
    "load_ir_dataset_qrels(\"cord19/trec-covid/round2\")\n",
    "load_ir_dataset_qrels(\"cord19/trec-covid/round3\")\n",
    "load_ir_dataset_qrels(\"cord19/trec-covid/round4\")\n",
    "load_ir_dataset_qrels(\"cord19/trec-covid/round5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_to_core_qrels(\"../data/qrels/cord19-trec-covid-round1.qrels\").to_csv(\"../data/qrels/trec-covid-round1.qrels-core_queries\", sep=\" \", header=None, index=False)\n",
    "limit_to_core_qrels(\"../data/qrels/cord19-trec-covid-round2.qrels\").to_csv(\"../data/qrels/trec-covid-round2.qrels-core_queries\", sep=\" \", header=None, index=False)\n",
    "limit_to_core_qrels(\"../data/qrels/cord19-trec-covid-round3.qrels\").to_csv(\"../data/qrels/trec-covid-round3.qrels-core_queries\", sep=\" \", header=None, index=False)\n",
    "limit_to_core_qrels(\"../data/qrels/cord19-trec-covid-round4.qrels\").to_csv(\"../data/qrels/trec-covid-round4.qrels-core_queries\", sep=\" \", header=None, index=False)\n",
    "limit_to_core_qrels(\"../data/qrels/cord19-trec-covid-round5.qrels\").to_csv(\"../data/qrels/trec-covid-round5.qrels-core_queries\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_table = load_runs_metadata_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in runs_table[runs_table[\"dataset\"] ==\"trec-covid\"].iterrows():\n",
    "    run = pd.read_csv(\"../data/run/\"+row.filename, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"rank\", \"score\", \"method\"])\n",
    "    run = run[run[\"qid\"]<=30]\n",
    "    run.to_csv(\"../data/run-core_queries/\"+row.filename, sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LongEval\n",
    "### qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel_paths = {\n",
    "    \"longeval-WT\": \"../data/dataset/LongEval/longeval-relevance-judgements/heldout-test.txt\",\n",
    "    \"longeval-WT-train\": \"../data/dataset/LongEval/publish/French/Qrels/train.txt\",\n",
    "    \"longeval-ST\": \"../data/dataset/LongEval/longeval-relevance-judgements/a-short-july.txt\",\n",
    "    \"longeval-LT\": \"../data/dataset/LongEval/longeval-relevance-judgements/b-long-september.txt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move normal qrels\n",
    "pd.read_csv(qrel_paths[\"longeval-ST\"], sep=\" \", header=None, names=[\"qid\", \"0\", \"doc_id\", \"relevance\"]).to_csv(\"../data/qrels/longeval-ST.qrels-test\", sep=\" \", header=None, index=False)\n",
    "pd.read_csv(qrel_paths[\"longeval-LT\"], sep=\" \", header=None, names=[\"qid\", \"0\", \"doc_id\", \"relevance\"]).to_csv(\"../data/qrels/longeval-LT.qrels-test\", sep=\" \", header=None, index=False)\n",
    "\n",
    "# move train qrels\n",
    "test = pd.read_csv(qrel_paths[\"longeval-WT\"], sep=\" \", header=None, names=[\"qid\", \"0\", \"doc_id\", \"relevance\"])\n",
    "train = pd.read_csv(qrel_paths[\"longeval-WT-train\"], sep=\" \", header=None, names=[\"qid\", \"0\", \"doc_id\", \"relevance\"])\n",
    "merged = pd.concat([test, train]).to_csv(\"../data/qrels/longeval-WT.qrels\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_qrels(path, subcollection, core_docs=False):\n",
    "    # load qrels\n",
    "    qrels = pd.read_csv(path, sep=\" \", header=None, names=[\"qid\", \"0\", \"docid\", \"relevance\"])\n",
    "\n",
    "    # prepare patches\n",
    "    longeval_core_docs = pd.read_csv(\"../evaluation/core_docs.tsv\", sep=\"\\t\", index_col=0)\n",
    "    patch_doc = longeval_core_docs[f\"docno_{subcollection}\"].reset_index()[[f\"docno_{subcollection}\", \"index\"]].set_index(f\"docno_{subcollection}\")[\"index\"].astype(str).to_dict()\n",
    "\n",
    "    longeval_core_queries = pd.read_csv(\"../evaluation/core_queries.tsv\", sep=\"\\t\", index_col=0)\n",
    "    patch_queries = longeval_core_queries[f\"qid_{subcollection}\"].reset_index()[[f\"qid_{subcollection}\", \"index\"]].set_index(f\"qid_{subcollection}\")[\"index\"].astype(str).to_dict()\n",
    "\n",
    "    if core_docs:\n",
    "        qrels[\"docid\"] = qrels[\"docid\"].apply(lambda x: patch_doc.get(x, None))\n",
    "    else:\n",
    "        qrels[\"docid\"] = qrels[\"docid\"].apply(lambda x: patch_doc.get(x, x))\n",
    "    qrels[\"qid\"] = qrels[\"qid\"].apply(lambda x: patch_queries.get(x, None))\n",
    "\n",
    "    qrels = qrels.dropna()\n",
    "\n",
    "    return qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_qrels(qrel_paths[\"longeval-ST\"], \"ST\").to_csv(\"../data/qrels/longeval-ST.qrels-test-core_queries\", sep=\" \", header=None, index=False)\n",
    "filter_qrels(qrel_paths[\"longeval-LT\"], \"LT\").to_csv(\"../data/qrels/longeval-LT.qrels-test-core_queries\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = filter_qrels(qrel_paths[\"longeval-WT\"], \"WT\")\n",
    "train = filter_qrels(qrel_paths[\"longeval-WT-train\"], \"WT\")\n",
    "merged = pd.concat([test, train]).to_csv(\"../data/qrels/longeval-WT.qrels-core_queries\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_run(row, core_docs=False):\n",
    "    run = pd.read_csv(\"../data/run/\"+row.filename, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"rank\", \"score\", \"method\"])\n",
    "    \n",
    "    # prepare patches\n",
    "    longeval_core_docs = pd.read_csv(\"../evaluation/core_docs.tsv\", sep=\"\\t\", index_col=0)\n",
    "    patch_doc = longeval_core_docs[f\"docno_{row.subcollection}\"].reset_index()[[f\"docno_{row.subcollection}\", \"index\"]].set_index(f\"docno_{row.subcollection}\")[\"index\"].astype(str).to_dict()\n",
    "\n",
    "    longeval_core_queries = pd.read_csv(\"../evaluation/core_queries.tsv\", sep=\"\\t\", index_col=0)\n",
    "    patch_queries = longeval_core_queries[f\"qid_{row.subcollection}\"].reset_index()[[f\"qid_{row.subcollection}\", \"index\"]].set_index(f\"qid_{row.subcollection}\")[\"index\"].astype(str).to_dict()\n",
    "\n",
    "    if core_docs:\n",
    "        run[\"docid\"] = run[\"docid\"].apply(lambda x: patch_doc.get(x, None))\n",
    "    else:\n",
    "        run[\"docid\"] = run[\"docid\"].apply(lambda x: patch_doc.get(x, x))\n",
    "    run[\"qid\"] = run[\"qid\"].apply(lambda x: patch_queries.get(x, None))\n",
    "\n",
    "    return run.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_table = load_runs_metadata_table()\n",
    "for _, row in runs_table[runs_table[\"dataset\"] ==\"longeval\"].iterrows():\n",
    "    run = filter_run(row)\n",
    "    run.to_csv(\"../data/run-core_queries/\"+row.filename, sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "longeval_core_queries = pd.read_csv(\"../evaluation/core_queries.tsv\", sep=\"\\t\", index_col=0)\n",
    "patch_queries = longeval_core_queries[f\"qid_WT\"].reset_index()[[f\"qid_WT\", \"index\"]].set_index(f\"qid_WT\")[\"index\"].astype(str).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_path = \"../data/index/index-longeval-WT-pyterrier/queries/full.trec\"\n",
    "topics = pt.io.read_topics(topics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[\"qid\"] = topics[\"qid\"].apply(lambda x: patch_queries.get(x, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.dropna().to_csv(\"longeval_topics_core_queries_unified.tsv\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pt.io.read_topics(\"longeval_topics_core_queries_unified.tsv\", format=\"singleline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>solar hot water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>the lord of the rings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>loa car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>one way car rental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>meteorological service of canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>148</td>\n",
       "      <td>sophie marceau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>149</td>\n",
       "      <td>sosh customer space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>151</td>\n",
       "      <td>sylvie retailleau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>105</td>\n",
       "      <td>land of france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>97</td>\n",
       "      <td>find my training pole job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                             query\n",
       "0    147                   solar hot water\n",
       "1    154             the lord of the rings\n",
       "2    108                           loa car\n",
       "3    125                one way car rental\n",
       "4     16  meteorological service of canada\n",
       "..   ...                               ...\n",
       "119  148                    sophie marceau\n",
       "120  149               sosh customer space\n",
       "121  151                 sylvie retailleau\n",
       "122  105                    land of france\n",
       "123   97         find my training pole job\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TripClick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../scripts/tripclick-subcollections.json\", \"r\") as file:\n",
    "    tripclick_subcollections = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripclick_subcollections = pd.DataFrame(tripclick_subcollections.items(), columns=[\"subcollection\", \"doc_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripklick_t1_docids = tripclick_subcollections[tripclick_subcollections[\"doc_id\"].isin([\"t1\", np.nan])][\"subcollection\"].to_list()  # some subcollections are nan because of missing metadata\n",
    "tripklick_t2_docids = tripclick_subcollections[tripclick_subcollections[\"doc_id\"].isin([\"t1\", \"t2\", np.nan])][\"subcollection\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565452, 1084487)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tripklick_t1_docids), len(tripklick_t2_docids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit qrels to core queries\n",
    "def limit_qrels_by_docs(qrels_file_path, doc_ids, dataset_name):\n",
    "    df = pd.read_csv(qrels_file_path, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"relevance\"])\n",
    "    df = df[df[\"docid\"].astype(str).isin(doc_ids)]\n",
    "    df.to_csv(f\"../data/qrels/{dataset_name}\", sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_qrels_by_docs(\"../data/dataset/TripClick/benchmark/qrels/qrels.dctr.head.test.txt\", tripklick_t1_docids, \"tripclick-test-head-t1.qrels-test-head-dctr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_qrels_by_docs(\"../data/dataset/TripClick/benchmark/qrels/qrels.dctr.head.test.txt\", tripklick_t2_docids, \"tripclick-test-head-t2.qrels-test-head-dctr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move full qrels for last subcollection\n",
    "!cp ../data/dataset/TripClick/benchmark/qrels/qrels.dctr.head.test.txt ../data/qrels/tripclick-test-head-t3.qrels-test-head-dctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move normal qrels\n",
    "!cp ../data/qrels/tripclick-test-head-t3.qrels-test-head-dctr ../data/qrels/tripclick-test-head-t3.qrels-test-head-dctr-core_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../data/qrels/tripclick-test-head-t2.qrels-test-head-dctr ../data/qrels/tripclick-test-head-t2.qrels-test-head-dctr-core_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../data/qrels/tripclick-test-head-t1.qrels-test-head-dctr ../data/qrels/tripclick-test-head-t1.qrels-test-head-dctr-core_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### runs\n",
    "the runs can be moved, all qrels are used at any time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in runs_table[runs_table[\"dataset\"] ==\"tripclick-test-head\"].iterrows():\n",
    "    run = pd.read_csv(\"../data/run/\"+row.filename, sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"rank\", \"score\", \"method\"])\n",
    "    run.to_csv(\"../data/run-core_queries/\"+row.filename, sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge LongEval WT Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "for run in os.listdir(\"../data/run\"):\n",
    "    parts = run.split(\"-\")\n",
    "    fields = {\"dataset\":  \"-\".join(parts[1:-4]),\n",
    "    \"subcollection\":  parts[-4],\n",
    "    \"queries\": parts[-3],\n",
    "    \"method\": parts[-2],\n",
    "    \"implementation\": parts[-1],\n",
    "    \"filename\": run}\n",
    "    table.append(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28003/3578907483.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  for method in df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][\"method\"].unique():\n",
      "/tmp/ipykernel_28003/3578907483.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n",
      "/tmp/ipykernel_28003/3578907483.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n",
      "/tmp/ipykernel_28003/3578907483.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n",
      "/tmp/ipykernel_28003/3578907483.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n",
      "/tmp/ipykernel_28003/3578907483.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n",
      "/tmp/ipykernel_28003/3578907483.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n",
      "/tmp/ipykernel_28003/3578907483.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n",
      "/tmp/ipykernel_28003/3578907483.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n"
     ]
    }
   ],
   "source": [
    "for method in df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][\"method\"].unique():\n",
    "    runs = df[df[\"dataset\"]==\"longeval\"][df[\"subcollection\"]==\"WT\"][df[\"method\"]==method][\"filename\"].to_list()\n",
    "    implementation = runs[0].split(\"-\")[-1]\n",
    "    full_run = pd.concat([pd.read_csv(base_path+runs[0], sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"rank\", \"score\", \"method\"]), pd.read_csv(base_path+runs[1], sep=\" \", header=None, names=[\"qid\", \"Q0\", \"docid\", \"rank\", \"score\", \"method\"])])\n",
    "    full_run.to_csv(f\"../data/run/run-longeval-WT-queries-{method}-{implementation}\", sep=\" \", header=None, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LongEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
